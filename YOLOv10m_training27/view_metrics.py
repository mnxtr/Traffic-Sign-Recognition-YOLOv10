#!/usr/bin/env python3
"""
Extract and display key metrics from YOLOv10m training visualizations
Shows text-based analysis of confusion matrix and performance curves
"""

from PIL import Image
import numpy as np
import sys

def analyze_confusion_matrix(image_path):
    """Analyze confusion matrix image and extract insights"""
    print("=" * 80)
    print("CONFUSION MATRIX ANALYSIS")
    print("=" * 80)
    
    img = Image.open(image_path)
    print(f"\nImage: {image_path}")
    print(f"Dimensions: {img.size[0]}x{img.size[1]} pixels")
    
    # The confusion matrix is a heatmap
    # We can analyze the general structure even without OCR
    
    print("\nğŸ“Š VISUAL CHARACTERISTICS:")
    print("  â€¢ This is a normalized confusion matrix (percentage-based)")
    print("  â€¢ Rows = True classes (actual traffic signs)")
    print("  â€¢ Columns = Predicted classes (what model detected)")
    print("  â€¢ Diagonal = Correct predictions (should be brightest)")
    print("  â€¢ Off-diagonal = Misclassifications (should be dark)")
    
    # Convert to numpy for basic analysis
    img_array = np.array(img.convert('RGB'))
    
    # Get average brightness (higher = better performance generally)
    avg_brightness = np.mean(img_array)
    
    print(f"\nğŸ’¡ QUICK ASSESSMENT:")
    print(f"  â€¢ Average image brightness: {avg_brightness:.1f}/255")
    
    if avg_brightness > 200:
        print("  â€¢ Overall: Likely high accuracy (bright confusion matrix)")
    elif avg_brightness > 150:
        print("  â€¢ Overall: Moderate accuracy")
    else:
        print("  â€¢ Overall: May have accuracy issues (dark matrix)")
    
    print("\nğŸ¯ TO PROPERLY READ THIS MATRIX:")
    print("  1. Look for a bright diagonal line (top-left to bottom-right)")
    print("  2. Check if off-diagonal areas are mostly dark/black")
    print("  3. Identify any bright spots off the diagonal (class confusions)")
    print("  4. Check row/column labels for class names/IDs")
    
    print("\nâœ… GOOD SIGNS:")
    print("  â€¢ Strong bright diagonal")
    print("  â€¢ Dark everywhere else")
    print("  â€¢ Each class >80% accuracy on diagonal")
    
    print("\nâš ï¸  WARNING SIGNS:")
    print("  â€¢ Dim diagonal elements (low accuracy for those classes)")
    print("  â€¢ Bright off-diagonal spots (systematic confusion)")
    print("  â€¢ Missing rows/columns (classes not detected)")
    
    return img_array

def analyze_pr_curve(image_path):
    """Analyze PR curve and extract insights"""
    print("\n" + "=" * 80)
    print("PRECISION-RECALL CURVE ANALYSIS")
    print("=" * 80)
    
    img = Image.open(image_path)
    print(f"\nImage: {image_path}")
    print(f"Dimensions: {img.size[0]}x{img.size[1]} pixels")
    
    print("\nğŸ“Š HOW TO READ THIS CURVE:")
    print("  â€¢ X-axis: Recall (0.0 to 1.0) - % of true signs found")
    print("  â€¢ Y-axis: Precision (0.0 to 1.0) - % of predictions that are correct")
    print("  â€¢ Curve shows trade-off between precision and recall")
    print("  â€¢ Area under curve = mAP (mean Average Precision)")
    
    print("\nğŸ¯ INTERPRETING THE SHAPE:")
    
    print("\n  EXCELLENT (mAP > 0.90):")
    print("    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â† Curve hugs top-right corner")
    print("  P â”‚ â”‚         â”‚ â”‚")
    print("    â”‚ â”‚         â””â”€â”¤")
    print("    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print("        Recall")
    
    print("\n  POOR (mAP < 0.60):")
    print("    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("    â”‚           â•² â”‚  â† Curve sags toward bottom-left")
    print("  P â”‚            â•²â”‚")
    print("    â”‚             â•²")
    print("    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print("        Recall")
    
    print("\nğŸ’¡ LOOK FOR:")
    print("  â€¢ mAP@0.5 value (usually shown in legend/title)")
    print("  â€¢ All classes curve (overall performance)")
    print("  â€¢ Individual class curves (per-sign performance)")
    
    print("\nğŸ“ PERFORMANCE BENCHMARKS:")
    print("  â€¢ mAP@0.5 > 0.90  = Excellent (production ready)")
    print("  â€¢ mAP@0.5 = 0.80-0.90 = Very good")
    print("  â€¢ mAP@0.5 = 0.70-0.80 = Good")
    print("  â€¢ mAP@0.5 = 0.60-0.70 = Fair (needs improvement)")
    print("  â€¢ mAP@0.5 < 0.60  = Poor (retrain needed)")

def analyze_f1_curve(image_path):
    """Analyze F1 curve"""
    print("\n" + "=" * 80)
    print("F1 SCORE CURVE ANALYSIS")
    print("=" * 80)
    
    img = Image.open(image_path)
    print(f"\nImage: {image_path}")
    print(f"Dimensions: {img.size[0]}x{img.size[1]} pixels")
    
    print("\nğŸ“Š PURPOSE:")
    print("  â€¢ Find optimal confidence threshold for inference")
    print("  â€¢ F1 = harmonic mean of Precision and Recall")
    print("  â€¢ Formula: F1 = 2 Ã— (P Ã— R) / (P + R)")
    
    print("\nğŸ¯ HOW TO USE:")
    print("  1. Find the peak of the curve")
    print("  2. Note the confidence value at that peak")
    print("  3. Use this threshold when running inference")
    
    print("\n  Example Curve:")
    print("    1.0 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("        â”‚       â•±â•²      â”‚")
    print("    0.8 â”‚     â•±    â•²    â”‚  â† Peak at ~0.35 confidence")
    print("  F     â”‚   â•±        â•²  â”‚")
    print("  1 0.6 â”‚ â•±            â•²â”‚")
    print("        â”‚â•±              â•²")
    print("    0.0 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print("        0.0   0.35   1.0")
    print("           Confidence")
    
    print("\nğŸ’¡ TYPICAL OPTIMAL THRESHOLDS:")
    print("  â€¢ 0.20-0.30: Maximize detections (high recall)")
    print("  â€¢ 0.30-0.40: Balanced performance (peak F1)")
    print("  â€¢ 0.50-0.70: Minimize false alarms (high precision)")
    
    print("\nâœ… GOOD PERFORMANCE:")
    print("  â€¢ Peak F1 > 0.80")
    print("  â€¢ Sharp peak (not flat)")
    print("  â€¢ All classes have similar F1 scores")
    
    print("\nâš ï¸  ISSUES:")
    print("  â€¢ Peak F1 < 0.60 (poor overall performance)")
    print("  â€¢ Flat curve (threshold insensitive, may indicate issues)")
    print("  â€¢ Large variation between classes")

def analyze_validation_batch(labels_path, pred_path):
    """Analyze validation batch comparison"""
    print("\n" + "=" * 80)
    print("VALIDATION BATCH COMPARISON")
    print("=" * 80)
    
    labels = Image.open(labels_path)
    preds = Image.open(pred_path)
    
    print(f"\nGround Truth: {labels_path}")
    print(f"  Dimensions: {labels.size[0]}x{labels.size[1]} pixels")
    
    print(f"\nPredictions: {pred_path}")
    print(f"  Dimensions: {preds.size[0]}x{preds.size[1]} pixels")
    
    print("\nğŸ“Š MOSAIC LAYOUT:")
    print("  Both images show a grid of validation samples")
    print("  Each cell contains:")
    print("    â€¢ Traffic sign image")
    print("    â€¢ Bounding boxes around detected signs")
    print("    â€¢ Class labels")
    
    print("\nğŸ¯ COMPARISON CHECKLIST:")
    
    print("\n  âœ… GOOD SIGNS (compare labels vs predictions):")
    print("    â€¢ Bounding boxes match in size and position")
    print("    â€¢ All signs in labels are also in predictions")
    print("    â€¢ Class labels are identical")
    print("    â€¢ Boxes are tight around signs (not too loose)")
    
    print("\n  âš ï¸  ISSUES TO LOOK FOR:")
    print("    â€¢ Missing detections: Box in labels but not in predictions")
    print("    â€¢ False positives: Box in predictions but not in labels")
    print("    â€¢ Wrong class: Different label in predictions vs labels")
    print("    â€¢ Loose boxes: Predictions have oversized bounding boxes")
    print("    â€¢ Position errors: Boxes don't align properly")
    
    print("\nğŸ’¡ VISUAL INSPECTION:")
    print("  1. Open both images side-by-side")
    print("  2. Look at same position in both images")
    print("  3. Count differences (missing, extra, wrong boxes)")
    print("  4. Estimate accuracy: # correct / # total signs")

def main():
    """Main analysis function"""
    print("\n" + "=" * 80)
    print(" " * 20 + "YOLOv10m TRAINING METRICS ANALYSIS")
    print(" " * 25 + "Training27 - Text-Based View")
    print("=" * 80)
    
    files = {
        'confusion_matrix_normalized.png': analyze_confusion_matrix,
        'PR_curve.png': analyze_pr_curve,
        'F1_curve.png': analyze_f1_curve,
    }
    
    # Analyze each metric file
    for filename, analyzer in files.items():
        try:
            analyzer(filename)
        except FileNotFoundError:
            print(f"\nâš ï¸  File not found: {filename}")
        except Exception as e:
            print(f"\nâŒ Error analyzing {filename}: {e}")
    
    # Validation batch
    try:
        analyze_validation_batch('val_batch0_labels.jpg', 'val_batch0_pred.jpg')
    except Exception as e:
        print(f"\nâŒ Error analyzing validation batch: {e}")
    
    print("\n" + "=" * 80)
    print("ğŸ“Œ SUMMARY")
    print("=" * 80)
    
    print("\nâœ¨ KEY METRICS TO EXTRACT (manually from images):")
    print("  1. Confusion Matrix:")
    print("     â†’ Check diagonal values (should be >80%)")
    print("     â†’ Note any bright off-diagonal spots")
    
    print("\n  2. PR Curve:")
    print("     â†’ Read mAP@0.5 value from legend")
    print("     â†’ Target: >0.80 for good performance")
    
    print("\n  3. F1 Curve:")
    print("     â†’ Find peak F1 value")
    print("     â†’ Note optimal confidence threshold")
    
    print("\n  4. Validation Batch:")
    print("     â†’ Count missed detections")
    print("     â†’ Count false positives")
    print("     â†’ Estimate overall accuracy")
    
    print("\nğŸ–¼ï¸  TO VIEW IMAGES:")
    print("  # In GUI environment:")
    print("  eog confusion_matrix_normalized.png")
    print("  eog PR_curve.png")
    print("  eog F1_curve.png")
    print("  eog val_batch0_labels.jpg val_batch0_pred.jpg")
    
    print("\n  # Or copy to local machine and open:")
    print("  scp user@server:path/to/*.png .")
    print("  open *.png  # macOS")
    print("  xdg-open *.png  # Linux")
    
    print("\n" + "=" * 80)
    print("Analysis complete! View the images to get actual metric values.")
    print("=" * 80 + "\n")

if __name__ == "__main__":
    main()
