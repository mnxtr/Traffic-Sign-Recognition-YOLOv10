# Quick Reference - View Training Metrics

## üìç File Locations

All metric images are in:
```
/home/mnxtr/Traffic-Sign-Recognition-YOLOv10/YOLOv10m_training27/
```

## üéØ Priority Order (What to View First)

### 1Ô∏è‚É£ Confusion Matrix (MOST IMPORTANT)
```bash
File: confusion_matrix_normalized.png
Size: 3000√ó2250 pixels, 186 KB
Status: ‚úÖ Available
Quick Analysis: Brightness 250.1/255 = LIKELY HIGH ACCURACY
```

**What to look for:**
- Strong diagonal line (bright squares)
- Dark off-diagonal areas
- Each class >80% on diagonal

### 2Ô∏è‚É£ Precision-Recall Curve
```bash
File: PR_curve.png
Size: 2250√ó1500 pixels, 97 KB
Status: ‚úÖ Available
```

**What to extract:**
- mAP@0.5 value (in legend or title)
- Target: >0.80 for good model

### 3Ô∏è‚É£ F1 Score Curve
```bash
File: F1_curve.png
Size: 2250√ó1500 pixels, 157 KB
Status: ‚úÖ Available
```

**What to extract:**
- Peak F1 value
- Confidence threshold at peak
- Use this threshold for inference

## üíª How to View

### Option 1: File Manager (Easiest)
1. Open file manager
2. Navigate to: `/home/mnxtr/Traffic-Sign-Recognition-YOLOv10/YOLOv10m_training27/`
3. Double-click images to open

### Option 2: Command Line
```bash
cd /home/mnxtr/Traffic-Sign-Recognition-YOLOv10/YOLOv10m_training27

# View all at once
eog *.png *.jpg &

# Or one by one
eog confusion_matrix_normalized.png
eog PR_curve.png
eog F1_curve.png
```

### Option 3: If No GUI Available
```bash
# Copy to your local machine
scp -r user@server:/home/mnxtr/Traffic-Sign-Recognition-YOLOv10/YOLOv10m_training27/*.png ~/Downloads/

# Then open locally
```

## üìä Quick Analysis Results

Based on automated analysis:

‚úÖ **Confusion Matrix**
- Average brightness: 250.1/255
- Interpretation: **Likely HIGH accuracy**
- This suggests strong performance across classes

‚ú® **Expected Performance Range**
- Probably: 80-95% accuracy
- Good diagonal definition
- Minimal class confusion

## üìù What to Note When Viewing

### From Confusion Matrix:
```
‚ñ° Diagonal values (each class accuracy)
  Class 0: ____%
  Class 1: ____%
  ...
  
‚ñ° Problem classes (if any):
  Class __: Only __% (needs more data)
  
‚ñ° Confused classes:
  Class __ confused with Class __: __% of time
```

### From PR Curve:
```
‚ñ° mAP@0.5 = ____
‚ñ° Overall assessment: ____________
‚ñ° Weakest class: ____
‚ñ° Strongest class: ____
```

### From F1 Curve:
```
‚ñ° Peak F1 score: ____
‚ñ° Optimal confidence: ____
‚ñ° Recommendation: Use conf=____ for inference
```

### From Validation Images:
```
‚ñ° Correctly detected: __/__
‚ñ° Missed signs: __
‚ñ° False positives: __
‚ñ° Visual accuracy estimate: ____%
```

## üöÄ Next Steps After Viewing

1. **If metrics are good (mAP >0.80, F1 >0.75):**
   - ‚úÖ Model is ready for testing
   - Set confidence threshold from F1 peak
   - Test on new images

2. **If metrics are moderate (mAP 0.60-0.80):**
   - ‚ö†Ô∏è Check confusion matrix for weak classes
   - Collect more data for those classes
   - Consider additional training

3. **If metrics are poor (mAP <0.60):**
   - ‚ùå Check for issues:
     - Class imbalance
     - Dataset quality
     - Training parameters

## üìö Helper Scripts Available

All in current directory:

1. **view_metrics.py** - Text-based analysis guide
2. **analyze_training.py** - Comprehensive documentation
3. **TRAINING_ANALYSIS.md** - Full reference manual

```bash
# Run any of these for help
python3 view_metrics.py
python3 analyze_training.py
cat TRAINING_ANALYSIS.md
```

---

**Quick Start:** Just open the images in file manager and compare with the checklists above!
