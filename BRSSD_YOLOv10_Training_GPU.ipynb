{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üö¶ BRSSD Traffic Sign Detection with YOLOv10\n",
        "## Bangladeshi Road Sign Symbol Dataset Training\n",
        "\n",
        "This notebook trains YOLOv10 on the BRSSD dataset using Google Colab's free GPU.\n",
        "\n",
        "### Setup Instructions:\n",
        "1. **Enable GPU**: Go to `Runtime` ‚Üí `Change runtime type` ‚Üí Select `GPU` (T4 recommended)\n",
        "2. **Run all cells** in order\n",
        "3. **Download trained model** at the end\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Step 1: Install Dependencies"
      ],
      "metadata": {
        "id": "install-deps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install ultralytics roboflow -q\n",
        "\n",
        "# Verify GPU availability\n",
        "import torch\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"GPU Setup Verification\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è WARNING: GPU not available! Please enable GPU in Runtime settings.\")\n",
        "print(f\"{'='*60}\\n\")"
      ],
      "metadata": {
        "id": "install-packages"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì• Step 2: Download BRSSD Dataset from Roboflow"
      ],
      "metadata": {
        "id": "download-dataset"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "import os\n",
        "\n",
        "# Your Roboflow API key\n",
        "API_KEY = \"8GeCUXQU6JPzxMaYOe4m\"  # Replace with your API key if different\n",
        "\n",
        "# Initialize Roboflow\n",
        "rf = Roboflow(api_key=API_KEY)\n",
        "\n",
        "# Download the BRSSD dataset\n",
        "print(\"Downloading BRSSD dataset from Roboflow...\")\n",
        "project = rf.workspace(\"mostafinafis\").project(\"road-sign-detection-in-bd\")\n",
        "dataset = project.version(1).download(\"yolov8\")\n",
        "\n",
        "print(f\"\\n‚úì Dataset downloaded to: {dataset.location}\")\n",
        "print(f\"\\nDataset structure:\")\n",
        "!ls -lh {dataset.location}"
      ],
      "metadata": {
        "id": "download-data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîç Step 3: Explore Dataset"
      ],
      "metadata": {
        "id": "explore-dataset"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "# Load and display dataset configuration\n",
        "data_yaml_path = f\"{dataset.location}/data.yaml\"\n",
        "with open(data_yaml_path, 'r') as f:\n",
        "    data_config = yaml.safe_load(f)\n",
        "\n",
        "print(\"Dataset Configuration:\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Number of classes: {data_config['nc']}\")\n",
        "print(f\"\\nClass names:\")\n",
        "for i, name in enumerate(data_config['names']):\n",
        "    print(f\"  {i}: {name}\")\n",
        "\n",
        "# Count images\n",
        "dataset_path = Path(dataset.location)\n",
        "train_imgs = len(list((dataset_path / 'train/images').glob('*.*')))\n",
        "val_imgs = len(list((dataset_path / 'valid/images').glob('*.*')))\n",
        "test_imgs = len(list((dataset_path / 'test/images').glob('*.*')))\n",
        "\n",
        "print(f\"\\nDataset Statistics:\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Training images: {train_imgs}\")\n",
        "print(f\"Validation images: {val_imgs}\")\n",
        "print(f\"Test images: {test_imgs}\")\n",
        "print(f\"Total images: {train_imgs + val_imgs + test_imgs}\")\n",
        "print(f\"{'='*60}\")"
      ],
      "metadata": {
        "id": "explore-data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üñºÔ∏è Step 4: Visualize Sample Images"
      ],
      "metadata": {
        "id": "visualize-samples"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "def visualize_samples(dataset_path, split='train', num_samples=6):\n",
        "    \"\"\"Visualize random samples from the dataset with labels\"\"\"\n",
        "    img_dir = Path(dataset_path) / split / 'images'\n",
        "    label_dir = Path(dataset_path) / split / 'labels'\n",
        "    \n",
        "    img_files = list(img_dir.glob('*.jpg')) + list(img_dir.glob('*.png'))\n",
        "    samples = random.sample(img_files, min(num_samples, len(img_files)))\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    axes = axes.ravel()\n",
        "    \n",
        "    for idx, img_path in enumerate(samples):\n",
        "        # Load image\n",
        "        img = cv2.imread(str(img_path))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        h, w = img.shape[:2]\n",
        "        \n",
        "        # Load corresponding label\n",
        "        label_path = label_dir / (img_path.stem + '.txt')\n",
        "        if label_path.exists():\n",
        "            with open(label_path, 'r') as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split()\n",
        "                    if len(parts) >= 5:\n",
        "                        cls_id, x_center, y_center, width, height = map(float, parts[:5])\n",
        "                        \n",
        "                        # Convert YOLO format to pixel coordinates\n",
        "                        x1 = int((x_center - width/2) * w)\n",
        "                        y1 = int((y_center - height/2) * h)\n",
        "                        x2 = int((x_center + width/2) * w)\n",
        "                        y2 = int((y_center + height/2) * h)\n",
        "                        \n",
        "                        # Draw bounding box\n",
        "                        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                        cv2.putText(img, str(int(cls_id)), (x1, y1-5),\n",
        "                                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "        \n",
        "        axes[idx].imshow(img)\n",
        "        axes[idx].set_title(f\"{img_path.name}\")\n",
        "        axes[idx].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize training samples\n",
        "print(\"Sample Training Images with Annotations:\")\n",
        "visualize_samples(dataset.location, 'train', 6)"
      ],
      "metadata": {
        "id": "visualize-imgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Step 5: Train YOLOv10 Model\n",
        "\n",
        "You can choose different model sizes:\n",
        "- **YOLOv10n** (nano): Fastest, smallest\n",
        "- **YOLOv10s** (small): Good balance\n",
        "- **YOLOv10m** (medium): Better accuracy\n",
        "- **YOLOv10l** (large): High accuracy\n",
        "- **YOLOv10x** (xlarge): Best accuracy, slower"
      ],
      "metadata": {
        "id": "train-model"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Training configuration\n",
        "MODEL_SIZE = 'n'  # Change to 's', 'm', 'l', or 'x' for different sizes\n",
        "EPOCHS = 100       # Number of epochs\n",
        "BATCH_SIZE = 16    # Batch size (adjust based on GPU memory)\n",
        "IMG_SIZE = 640     # Image size\n",
        "\n",
        "# Initialize model\n",
        "model = YOLO(f'yolov10{MODEL_SIZE}.pt')\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Training YOLOv10-{MODEL_SIZE.upper()} on BRSSD Dataset\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Model: yolov10{MODEL_SIZE}.pt\")\n",
        "print(f\"Epochs: {EPOCHS}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Image size: {IMG_SIZE}\")\n",
        "print(f\"Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# Train the model\n",
        "results = model.train(\n",
        "    data=data_yaml_path,\n",
        "    epochs=EPOCHS,\n",
        "    imgsz=IMG_SIZE,\n",
        "    batch=BATCH_SIZE,\n",
        "    name=f'YOLOv10{MODEL_SIZE}_BRSSD_GPU',\n",
        "    patience=50,\n",
        "    save=True,\n",
        "    device=0,  # Use GPU\n",
        "    workers=8,\n",
        "    project='runs/detect',\n",
        "    exist_ok=True,\n",
        "    pretrained=True,\n",
        "    optimizer='auto',\n",
        "    verbose=True,\n",
        "    seed=42,\n",
        "    deterministic=True,\n",
        "    val=True,\n",
        "    plots=True,\n",
        "    \n",
        "    # Data augmentation\n",
        "    hsv_h=0.015,\n",
        "    hsv_s=0.7,\n",
        "    hsv_v=0.4,\n",
        "    degrees=0.0,\n",
        "    translate=0.1,\n",
        "    scale=0.5,\n",
        "    shear=0.0,\n",
        "    perspective=0.0,\n",
        "    flipud=0.0,\n",
        "    fliplr=0.5,\n",
        "    mosaic=1.0,\n",
        "    mixup=0.0,\n",
        ")\n",
        "\n",
        "print(\"\\n‚úì Training completed!\")"
      ],
      "metadata": {
        "id": "train-yolo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Step 6: Evaluate Model Performance"
      ],
      "metadata": {
        "id": "evaluate-model"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate the model\n",
        "print(\"Running validation on test set...\")\n",
        "metrics = model.val()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Validation Metrics\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
        "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall: {metrics.box.mr:.4f}\")\n",
        "print(f\"{'='*60}\\n\")"
      ],
      "metadata": {
        "id": "evaluate"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìà Step 7: Visualize Training Results"
      ],
      "metadata": {
        "id": "visualize-results"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Display training results\n",
        "results_dir = f'runs/detect/YOLOv10{MODEL_SIZE}_BRSSD_GPU'\n",
        "\n",
        "print(\"Training Curves:\")\n",
        "display(Image(filename=f'{results_dir}/results.png', width=800))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "display(Image(filename=f'{results_dir}/confusion_matrix.png', width=800))\n",
        "\n",
        "print(\"\\nPR Curve:\")\n",
        "display(Image(filename=f'{results_dir}/PR_curve.png', width=800))\n",
        "\n",
        "print(\"\\nF1 Curve:\")\n",
        "display(Image(filename=f'{results_dir}/F1_curve.png', width=800))"
      ],
      "metadata": {
        "id": "display-results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéØ Step 8: Test Model on Sample Images"
      ],
      "metadata": {
        "id": "test-model"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# Load best model\n",
        "best_model = YOLO(f'{results_dir}/weights/best.pt')\n",
        "\n",
        "# Get test images\n",
        "test_img_dir = Path(dataset.location) / 'test/images'\n",
        "test_images = list(test_img_dir.glob('*.jpg'))[:6]  # First 6 test images\n",
        "\n",
        "# Run predictions\n",
        "print(\"Running predictions on test images...\\n\")\n",
        "results_list = best_model.predict(test_images, conf=0.25, save=True)\n",
        "\n",
        "# Display predictions\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, (img_path, result) in enumerate(zip(test_images, results_list)):\n",
        "    img = result.plot()  # Plot predictions on image\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    axes[idx].imshow(img)\n",
        "    axes[idx].set_title(f\"{img_path.name}\")\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Model Predictions on Test Images', fontsize=16, y=1.02)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úì Predictions completed!\")"
      ],
      "metadata": {
        "id": "test-predictions"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üíæ Step 9: Download Trained Model"
      ],
      "metadata": {
        "id": "download-model"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Create a zip file with the trained model and results\n",
        "output_zip = f'YOLOv10{MODEL_SIZE}_BRSSD_trained'\n",
        "shutil.make_archive(output_zip, 'zip', results_dir)\n",
        "\n",
        "print(f\"Model and results archived to: {output_zip}.zip\")\n",
        "print(f\"\\nBest model weights: {results_dir}/weights/best.pt\")\n",
        "print(f\"Last model weights: {results_dir}/weights/last.pt\")\n",
        "\n",
        "# Download the best weights\n",
        "print(\"\\nDownloading best model weights...\")\n",
        "files.download(f'{results_dir}/weights/best.pt')\n",
        "\n",
        "# Optionally download the entire results folder\n",
        "print(\"\\nTo download all results (training curves, confusion matrix, etc.):\")\n",
        "print(f\"Uncomment the line below to download {output_zip}.zip\")\n",
        "# files.download(f'{output_zip}.zip')\n",
        "\n",
        "print(\"\\n‚úì Model download complete!\")"
      ],
      "metadata": {
        "id": "download-weights"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîÑ Step 10: Export Model (Optional)\n",
        "\n",
        "Export the model to different formats for deployment."
      ],
      "metadata": {
        "id": "export-model"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model\n",
        "best_model = YOLO(f'{results_dir}/weights/best.pt')\n",
        "\n",
        "# Export to ONNX format (for wider compatibility)\n",
        "print(\"Exporting to ONNX format...\")\n",
        "best_model.export(format='onnx')\n",
        "\n",
        "# Export to TensorFlow Lite (for mobile deployment)\n",
        "# print(\"Exporting to TensorFlow Lite...\")\n",
        "# best_model.export(format='tflite')\n",
        "\n",
        "# Export to TensorRT (for NVIDIA GPUs)\n",
        "# print(\"Exporting to TensorRT...\")\n",
        "# best_model.export(format='engine')\n",
        "\n",
        "print(\"\\n‚úì Model export complete!\")"
      ],
      "metadata": {
        "id": "export-formats"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìù Step 11: Save Training Summary"
      ],
      "metadata": {
        "id": "save-summary"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Create training summary\n",
        "summary = {\n",
        "    'model': f'YOLOv10{MODEL_SIZE}',\n",
        "    'dataset': 'BRSSD (Bangladeshi Road Sign Symbol Dataset)',\n",
        "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'epochs': EPOCHS,\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'image_size': IMG_SIZE,\n",
        "    'num_classes': data_config['nc'],\n",
        "    'class_names': data_config['names'],\n",
        "    'training_images': train_imgs,\n",
        "    'validation_images': val_imgs,\n",
        "    'test_images': test_imgs,\n",
        "    'metrics': {\n",
        "        'mAP50': float(metrics.box.map50),\n",
        "        'mAP50-95': float(metrics.box.map),\n",
        "        'precision': float(metrics.box.mp),\n",
        "        'recall': float(metrics.box.mr)\n",
        "    },\n",
        "    'device': 'GPU' if torch.cuda.is_available() else 'CPU',\n",
        "    'weights_path': f'{results_dir}/weights/best.pt'\n",
        "}\n",
        "\n",
        "# Save summary to JSON\n",
        "summary_path = f'{results_dir}/training_summary.json'\n",
        "with open(summary_path, 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "# Display summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(json.dumps(summary, indent=2))\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n‚úì Training summary saved to: {summary_path}\")"
      ],
      "metadata": {
        "id": "save-summary"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéâ Training Complete!\n",
        "\n",
        "Your YOLOv10 model has been successfully trained on the BRSSD dataset!\n",
        "\n",
        "### Next Steps:\n",
        "1. ‚úÖ Download the trained model weights (`best.pt`)\n",
        "2. ‚úÖ Review the training metrics and visualizations\n",
        "3. ‚úÖ Test the model on your own images\n",
        "4. ‚úÖ Deploy the model in your application\n",
        "\n",
        "### Model Files:\n",
        "- **Best weights**: `runs/detect/YOLOv10{MODEL_SIZE}_BRSSD_GPU/weights/best.pt`\n",
        "- **Last weights**: `runs/detect/YOLOv10{MODEL_SIZE}_BRSSD_GPU/weights/last.pt`\n",
        "- **Training results**: `runs/detect/YOLOv10{MODEL_SIZE}_BRSSD_GPU/`\n",
        "\n",
        "### Using the Trained Model:\n",
        "```python\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load your trained model\n",
        "model = YOLO('path/to/best.pt')\n",
        "\n",
        "# Run inference\n",
        "results = model.predict('path/to/image.jpg', conf=0.25)\n",
        "\n",
        "# Display results\n",
        "results[0].show()\n",
        "```\n",
        "\n",
        "---\n",
        "**Happy detecting! üö¶**"
      ],
      "metadata": {
        "id": "conclusion"
      }
    }
  ]
}
