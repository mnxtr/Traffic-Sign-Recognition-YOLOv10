{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BRSSD Traffic Sign Recognition with YOLOv10\n",
    "## Bangladeshi Road Sign Symbol Dataset\n",
    "\n",
    "This notebook trains YOLOv10 models on the BRSSD dataset for detecting and recognizing Bangladeshi traffic signs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q ultralytics roboflow kaggle opencv-python pillow matplotlib seaborn pyyaml\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import shutil\n",
    "\n",
    "print(\"✓ Packages installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download BRSSD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Download from Roboflow\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# Enter your Roboflow API key\n",
    "API_KEY = \"YOUR_ROBOFLOW_API_KEY\"  # Get from https://app.roboflow.com/settings/api\n",
    "\n",
    "rf = Roboflow(api_key=API_KEY)\n",
    "# Update workspace and project name based on actual BRSSD location\n",
    "project = rf.workspace(\"YOUR_WORKSPACE\").project(\"brssd\")\n",
    "dataset = project.version(1).download(\"yolov8\", location=\"./BRSSD\")\n",
    "\n",
    "print(\"✓ Dataset downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Use pre-downloaded dataset or run download script\n",
    "!python3 download_brssd.py --source all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: Manual setup - if you've already downloaded BRSSD\n",
    "# Ensure your dataset is structured as:\n",
    "# BRSSD/\n",
    "#   train/images/\n",
    "#   train/labels/\n",
    "#   val/images/\n",
    "#   val/labels/\n",
    "#   test/images/  (optional)\n",
    "#   test/labels/  (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset structure\n",
    "dataset_path = Path(\"./BRSSD\")\n",
    "\n",
    "train_images = list((dataset_path / \"train/images\").glob(\"*.*\"))\n",
    "train_labels = list((dataset_path / \"train/labels\").glob(\"*.txt\"))\n",
    "val_images = list((dataset_path / \"val/images\").glob(\"*.*\"))\n",
    "val_labels = list((dataset_path / \"val/labels\").glob(\"*.txt\"))\n",
    "\n",
    "print(f\"Dataset Statistics:\")\n",
    "print(f\"  Training: {len(train_images)} images, {len(train_labels)} labels\")\n",
    "print(f\"  Validation: {len(val_images)} images, {len(val_labels)} labels\")\n",
    "\n",
    "# Load configuration\n",
    "with open('brssd_data.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    \n",
    "print(f\"\\nClasses ({config['nc']}):\")\n",
    "for idx, name in config['names'].items():\n",
    "    print(f\"  {idx}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display random training images with annotations\n",
    "import random\n",
    "\n",
    "def plot_annotated_images(num_samples=6):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    samples = random.sample(train_images, min(num_samples, len(train_images)))\n",
    "    \n",
    "    for idx, img_path in enumerate(samples):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Read corresponding label\n",
    "        label_path = dataset_path / \"train/labels\" / f\"{img_path.stem}.txt\"\n",
    "        \n",
    "        if label_path.exists():\n",
    "            with open(label_path, 'r') as f:\n",
    "                annotations = f.readlines()\n",
    "            \n",
    "            h, w = img.shape[:2]\n",
    "            for ann in annotations:\n",
    "                parts = ann.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id, x_center, y_center, width, height = map(float, parts[:5])\n",
    "                    \n",
    "                    # Convert YOLO format to pixel coordinates\n",
    "                    x1 = int((x_center - width/2) * w)\n",
    "                    y1 = int((y_center - height/2) * h)\n",
    "                    x2 = int((x_center + width/2) * w)\n",
    "                    y2 = int((y_center + height/2) * h)\n",
    "                    \n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    class_name = config['names'].get(int(class_id), f\"Class {int(class_id)}\")\n",
    "                    cv2.putText(img, class_name, (x1, y1-10), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(img_path.name)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_annotated_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize YOLOv10 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model size: n (nano), s (small), m (medium), l (large), x (extra large)\n",
    "MODEL_SIZE = 'n'  # Start with nano for faster training\n",
    "\n",
    "model = YOLO(f'yolov10{MODEL_SIZE}.pt')\n",
    "print(f\"✓ YOLOv10-{MODEL_SIZE.upper()} model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "results = model.train(\n",
    "    data='brssd_data.yaml',\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    name=f'YOLOv10{MODEL_SIZE}_BRSSD',\n",
    "    patience=50,\n",
    "    save=True,\n",
    "    device=0,  # 0 for GPU, 'cpu' for CPU\n",
    "    workers=8,\n",
    "    project='runs/brssd',\n",
    "    exist_ok=True,\n",
    "    pretrained=True,\n",
    "    optimizer='auto',\n",
    "    verbose=True,\n",
    "    seed=42,\n",
    "    val=True,\n",
    "    plots=True,\n",
    "    \n",
    "    # Augmentation\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    degrees=0.0,\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    fliplr=0.5,\n",
    "    mosaic=1.0,\n",
    "    \n",
    "    # Learning rate\n",
    "    lr0=0.01,\n",
    "    lrf=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate on test/validation set\n",
    "metrics = model.val()\n",
    "\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(f\"  mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"  mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"  Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"  Recall: {metrics.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model = YOLO(f'runs/brssd/YOLOv10{MODEL_SIZE}_BRSSD/weights/best.pt')\n",
    "\n",
    "# Predict on validation images\n",
    "test_images = random.sample(val_images, min(6, len(val_images)))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, img_path in enumerate(test_images):\n",
    "    results = best_model.predict(str(img_path), conf=0.25)\n",
    "    \n",
    "    # Plot results\n",
    "    annotated = results[0].plot()\n",
    "    annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    axes[idx].imshow(annotated)\n",
    "    axes[idx].axis('off')\n",
    "    axes[idx].set_title(f'Prediction: {img_path.name}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to different formats\n",
    "best_model.export(format='onnx')  # ONNX format\n",
    "# best_model.export(format='torchscript')  # TorchScript\n",
    "# best_model.export(format='tflite')  # TensorFlow Lite\n",
    "\n",
    "print(\"✓ Model exported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Real-time Inference (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on custom image\n",
    "# Upload your own image and test\n",
    "\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# for filename in uploaded.keys():\n",
    "#     results = best_model.predict(filename, conf=0.25)\n",
    "#     results[0].show()\n",
    "#     print(f\"Detected {len(results[0].boxes)} traffic signs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
